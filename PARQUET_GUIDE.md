"""Data Format Conversion and Fast I/O Guide

This guide explains the Excel-to-Parquet conversion for 5-10x I/O speedup
on top of the parallel processing speedup.

========================================
QUICK START: 5-MINUTE SETUP
========================================

Step 1: Install PyArrow (one-time setup)
-----------------------------------------
pip install pyarrow


Step 2: Convert Excel to Parquet (one-time)
--------------------------------------------
# Full conversion (takes ~5-10 minutes)
python scripts/convert_excel_to_parquet.py

# Quick test with 5 securities
python scripts/convert_excel_to_parquet.py --max-sheets 5

Output: data/parquet/{security}.parquet files


Step 3: Run Backtest with Parquet
----------------------------------
# Use Parquet with parallel processing
python scripts/run_parquet_backtest.py --strategy v1_baseline

# Quick test
python scripts/run_parquet_backtest.py --strategy v1_baseline --max-sheets 5


========================================
PERFORMANCE COMPARISON
========================================

EXCEL (Sequential):
  - Runtime: 8-10 minutes
  - Bottleneck: Single-threaded I/O
  - Memory: 500MB-1GB
  
EXCEL (Parallel):
  - Runtime: 2-3 minutes (4 cores)
  - Bottleneck: Excel sheet locking
  - Speedup: 3-4x
  
PARQUET (Parallel): ‚≠ê BEST
  - Runtime: 30-60 seconds (4 cores)
  - Bottleneck: None
  - Speedup: 8-15x vs sequential
  - Benefits:
    ‚úì 5-10x faster I/O
    ‚úì No sheet locking
    ‚úì 50% smaller files
    ‚úì True parallel reads

========================================
CONVERSION DETAILS
========================================

What the Conversion Does:
--------------------------
1. Reads Excel sheets one-by-one
2. Normalizes column names
3. Combines Date+Time to timestamp
4. Writes per-security Parquet files
5. Applies compression (snappy by default)

Output Structure:
-----------------
data/parquet/
‚îú‚îÄ‚îÄ adcb.parquet         (~8 MB)
‚îú‚îÄ‚îÄ adib.parquet         (~12 MB)
‚îú‚îÄ‚îÄ adnocgas.parquet     (~15 MB)
‚îú‚îÄ‚îÄ adnocdri.parquet     (~10 MB)
‚îú‚îÄ‚îÄ ...                  (16 files total)

File Sizes:
-----------
Excel:   ~100 MB (single file)
Parquet: ~50-60 MB (16 files, compressed)
Savings: ~40-50% disk space


========================================
USAGE EXAMPLES
========================================

Example 1: Basic Conversion
----------------------------
python scripts/convert_excel_to_parquet.py

Output:
  ‚úì ADNOCGAS: 42,347 rows ‚Üí adnocgas.parquet (15.2 MB)
  ‚úì EMAAR: 38,901 rows ‚Üí emaar.parquet (14.1 MB)
  ...
  CONVERSION COMPLETE: 16 securities in 5.3 minutes


Example 2: Test Conversion (5 Securities)
------------------------------------------
python scripts/convert_excel_to_parquet.py --max-sheets 5

Output:
  ‚úì Converted: 5/5 sheets
  ‚úì Total rows: 210,845
  ‚úì Time: 1.2 minutes


Example 3: Custom Output Directory
-----------------------------------
python scripts/convert_excel_to_parquet.py --output my_data/parquet


Example 4: Different Compression
---------------------------------
# Slower but smaller files
python scripts/convert_excel_to_parquet.py --compression gzip

# Faster but larger files
python scripts/convert_excel_to_parquet.py --compression none


========================================
PARQUET BACKTEST USAGE
========================================

Basic Usage:
------------
python scripts/run_parquet_backtest.py --strategy v1_baseline

This automatically uses data/parquet/ instead of Excel.


All Options:
------------
python scripts/run_parquet_backtest.py \\
    --strategy v1_baseline \\
    --parquet-dir data/parquet \\
    --workers 4 \\
    --max-sheets 5 \\
    --chunk-size 100000


Comparison Test:
----------------
# Run Excel sequential
python scripts/run_strategy.py --strategy v1_baseline --max-sheets 5

# Run Excel parallel
python scripts/run_parallel_backtest.py --strategy v1_baseline --max-sheets 5

# Run Parquet parallel
python scripts/run_parquet_backtest.py --strategy v1_baseline --max-sheets 5

# Compare timings!


========================================
TECHNICAL DETAILS
========================================

Parquet Benefits:
-----------------
1. Columnar Storage
   - Only reads columns you need
   - Better compression
   - Faster filtering

2. No Sheet Locking
   - Excel: Only one sheet read at a time
   - Parquet: All files read in parallel
   
3. Zero Parsing Overhead
   - Excel: openpyxl parsing is slow
   - Parquet: Direct binary read

4. Native Pandas Integration
   - df = pd.read_parquet(file)
   - Optimized C++ engine
   
5. Metadata Support
   - Schema stored in file
   - Statistics for fast filtering


Compression Options:
--------------------
snappy (default):
  - Fast compression/decompression
  - Moderate compression ratio
  - Best for backtesting
  
gzip:
  - Slower but smaller files
  - Good for archival
  - 20-30% smaller than snappy
  
none:
  - No compression
  - Fastest I/O
  - 2x larger files


========================================
VALIDATION & TROUBLESHOOTING
========================================

Verify Conversion:
------------------
# List generated files
python -c "from pathlib import Path; print(*Path('data/parquet').glob('*.parquet'), sep='\\n')"

# Check file sizes
python -c "from pathlib import Path; print(sum(f.stat().st_size for f in Path('data/parquet').glob('*.parquet')) / 1024**2, 'MB')"

# Read sample data
python -c "import pandas as pd; df = pd.read_parquet('data/parquet/adnocgas.parquet'); print(df.head())"


Common Issues:
--------------
ERROR: pyarrow not installed
‚Üí pip install pyarrow

ERROR: Parquet file not found
‚Üí Run convert_excel_to_parquet.py first

ERROR: Missing columns
‚Üí Check Excel file has Date, Time, Type, Price, Volume

WARNING: High memory usage
‚Üí Reduce --chunk-size (e.g., 50000)


Compare Results:
----------------
# Run both versions and compare outputs
python scripts/test_parallel_backtest.py

This verifies Parquet produces identical results to Excel.


========================================
RECOMMENDED WORKFLOW
========================================

Development Cycle:
------------------
1. First time:
   - Convert Excel to Parquet (one-time)
   - Verify with test run
   
2. Daily development:
   - Use Parquet for all testing
   - Fast iteration cycles
   
3. Final validation:
   - Run both Excel and Parquet
   - Compare results
   - Use Excel as ground truth


Parameter Sweeps:
-----------------
# Convert once
python scripts/convert_excel_to_parquet.py

# Run fast sweeps
python scripts/run_parquet_backtest.py --strategy v1_baseline
python scripts/run_parquet_backtest.py --strategy v2_price_follow_qty_cooldown

# Each sweep: 30-60 seconds instead of 8-10 minutes!


Production Deployment:
----------------------
1. Convert Excel to Parquet
2. Test thoroughly
3. Use Parquet for production
4. Keep Excel as backup/validation


========================================
MIGRATION CHECKLIST
========================================

‚òê Install pyarrow
   pip install pyarrow

‚òê Convert Excel data
   python scripts/convert_excel_to_parquet.py
   
‚òê Verify conversion
   Check data/parquet/ directory has 16 .parquet files
   
‚òê Test with 5 sheets
   python scripts/run_parquet_backtest.py --strategy v1_baseline --max-sheets 5
   
‚òê Compare against Excel
   python scripts/test_parallel_backtest.py
   
‚òê Full production run
   python scripts/run_parquet_backtest.py --strategy v1_baseline
   
‚òê Measure speedup
   Compare timing vs Excel versions


========================================
FAQ
========================================

Q: Do I need to reconvert if Excel changes?
A: Yes, rerun convert_excel_to_parquet.py

Q: Can I delete the Excel file after conversion?
A: Keep it as backup for validation

Q: Will Parquet results match Excel exactly?
A: Yes, identical data ‚Üí identical results

Q: Can I use Parquet with sequential backtest?
A: Yes, but parallel + Parquet gives maximum speedup

Q: What if I only want to convert some securities?
A: Use --max-sheets or edit script to filter

Q: How do I add new securities?
A: Add to Excel, rerun conversion


========================================
NEXT STEPS
========================================

1. Install pyarrow:
   pip install pyarrow

2. Run conversion:
   python scripts/convert_excel_to_parquet.py

3. Test run:
   python scripts/run_parquet_backtest.py --strategy v1_baseline --max-sheets 5

4. Enjoy 8-15x speedup! üöÄ
